"use strict";(self.webpackChunkkgkb=self.webpackChunkkgkb||[]).push([[41924],{80973:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var s=t(74848),a=t(28453);const o={slug:"install-pihole-rpi4-microk8s-ubuntu-2004",title:"Installing PiHole On Raspberry Pi 4, MicroK8s running Ubuntu 20.04\xa0(focal)",description:"Fill me up!",authors:["kbbgl"],tags:["docker","how-to","k8s","kubernetes","linux","pihole","raspberry_pi","troubleshooting"]},i=void 0,l={permalink:"/blog/install-pihole-rpi4-microk8s-ubuntu-2004",source:"@site/blog/install-pihole-rpi4-microk8s-ubuntu-2004.md",title:"Installing PiHole On Raspberry Pi 4, MicroK8s running Ubuntu 20.04\xa0(focal)",description:"Fill me up!",date:"2024-09-26T20:02:05.000Z",tags:[{inline:!1,label:"Docker",permalink:"/blog/tags/docker"},{inline:!1,label:"How-to",permalink:"/blog/tags/how-to"},{inline:!1,label:"K8s",permalink:"/blog/tags/k-8-s"},{inline:!1,label:"Kubernetes",permalink:"/blog/tags/kubernetes"},{inline:!1,label:"Linux",permalink:"/blog/tags/linux"},{inline:!1,label:"Pihole",permalink:"/blog/tags/pihole"},{inline:!1,label:"Raspberry_pi",permalink:"/blog/tags/raspberry-pi"},{inline:!1,label:"Troubleshooting",permalink:"/blog/tags/troubleshooting"}],readingTime:16.835,hasTruncateMarker:!0,authors:[{name:"Kobbi Gal",title:"I like to pick things apart and see how they work inside",url:"https://github.com/kbbgl",imageURL:"https://avatars.githubusercontent.com/u/14372649",key:"kbbgl",page:null}],frontMatter:{slug:"install-pihole-rpi4-microk8s-ubuntu-2004",title:"Installing PiHole On Raspberry Pi 4, MicroK8s running Ubuntu 20.04\xa0(focal)",description:"Fill me up!",authors:["kbbgl"],tags:["docker","how-to","k8s","kubernetes","linux","pihole","raspberry_pi","troubleshooting"]},unlisted:!1,prevItem:{title:"How To Trace/Read RabbitMQ\xa0Messages",permalink:"/blog/how-to-trace-read-rabbitmq\xa0messages"},nextItem:{title:"Installing Ubuntu 20.04 on 2013 MacBook\xa0Air",permalink:"/blog/installing-ubuntu-2004-on-2013-macbook-air"}},r={authorsImageUrls:[void 0]},c=[{value:"PiHole, What\u2019s That?",id:"pihole-whats-that",level:2},{value:"Setting Up Kubernetes on Ubuntu",id:"setting-up-kubernetes-on-ubuntu",level:2},{value:"Creating Storage and Kubernetes Resources",id:"creating-storage-and-kubernetes-resources",level:2},{value:"Troubleshooting PiHole Pod CrashLoopBackOff",id:"troubleshooting-pihole-pod-crashloopbackoff",level:2},{value:"Installing Docker to Troubleshoot Image Initialization Failure",id:"installing-docker-to-troubleshoot-image-initialization-failure",level:2},{value:"Changing DNS Settings on Devices",id:"changing-dns-settings-on-devices",level:2},{value:"Setting Up Static IP for the Cluster",id:"setting-up-static-ip-for-the-cluster",level:2},{value:"Maintenance, <code>kubectl drain/uncordon</code>",id:"maintenance-kubectl-drainuncordon",level:2}];function h(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"pihole-whats-that",children:"PiHole, What\u2019s That?"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Pi-hole",children:"Wikipedia definition"})," should be sufficient in explaining what the software does:"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:"Pi-hole or Pihole is a Linux network-level advertisement and Internet tracker blocking application which acts as a DNS sinkhole and optionally a DHCP server, intended for use on a private network"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"I wanted to deploy it for a few reasons:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"I have a spare Raspberry Pi 4 lying around."}),"\n",(0,s.jsx)(n.li,{children:"Because I\u2019m working on getting my CKAD (Certified Kubernetes Application Developer) certification and thought it would be a great hands-on practice."}),"\n",(0,s.jsx)(n.li,{children:"I couldn\u2019t find a good enough article that described how to install PiHole on Kubernetes. The majority did not go throught the whole procedure, were aimed for Docker/Swarm and Raspbian (Raspberry Pi flavored Linux distribution)."}),"\n",(0,s.jsx)(n.li,{children:"I got tired of all the advertisements and popups on all the devices while surfing the web at home."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This post is here to explain how was able to deploy PiHole on Kubernetes and how I resolved some of the problems that occurred during the deployment process."}),"\n",(0,s.jsx)(n.h2,{id:"setting-up-kubernetes-on-ubuntu",children:"Setting Up Kubernetes on Ubuntu"}),"\n",(0,s.jsx)(n.p,{children:"There are a few ways to do this. I was looking at the different options but decided to choose MicroK8s in the end (over Charmed Kubernetes or kubeadm) simply because the Canonical team maintains it (Canonical is the publisher of Ubuntu) so I thought it would be the wisest decision long term as any kernel/software upgrades on the OS level would likely be QA\u2019d in the future in accordance with MicroK8s maintenance.\nSince MicroK8s is bundled as a snap (an additional package manager for Ubuntu), it already includes all the binaries necessary to set up Kubernetes. So we can run the following command to install it:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo snap install microk8s --classic\n"})}),"\n",(0,s.jsx)(n.p,{children:"We also need to ensure that we\u2019re allowing the different Kubernetes components to communicate with each other. To modify the firewall settings, we run the following:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo ufw allow in on cni0 && sudo ufw allow out on cni0\nsudo ufw default allow routed\n"})}),"\n",(0,s.jsx)(n.p,{children:"We also need to enable a DNS for the Kubernetes deployment. To do this we run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"microk8s enable dns\n"})}),"\n",(0,s.jsx)(n.p,{children:"We can then verify that the basic Kubernetes resources are up and running by:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"microk8s kubectl get all --all-namespaces\n"})}),"\n",(0,s.jsxs)(n.p,{children:["We should see that the kube-system namespace has the CNI (by  default Calico) controllers and node, coredns are running.\nYou may have noticed that we need to prefix the ",(0,s.jsx)(n.code,{children:"kubectl"})," commands with microk8s, which bothered me a bit because I was used to interacting with the Kubernetes API server using only ",(0,s.jsx)(n.code,{children:"kubectl [ACTION] [RESOURCE]"}),". I decided to install ",(0,s.jsx)(n.code,{children:"kubectl"})," from the ",(0,s.jsx)(n.code,{children:"snap"})," store to prevent typing out an extra prefix:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"snap install kubectl --classic\n"})}),"\n",(0,s.jsx)(n.p,{children:"We now have a running bare Kubernetes single node and ready to create all the necessary resources!"}),"\n",(0,s.jsx)(n.h2,{id:"creating-storage-and-kubernetes-resources",children:"Creating Storage and Kubernetes Resources"}),"\n",(0,s.jsx)(n.p,{children:"One of the great advantages of Kubernetes is the ability to isolate applications into their own scope, called Namespaces. Since I did see myself using the cluster for other projects in the future, I thought it would be practical to separate the Pihole project from the future projects into its own Namespace. To create the new namespace, I ran the following:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl create namespace pihole\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Since all of the following commands will be run in this namespace (and we want to save typing ",(0,s.jsx)(n.code,{children:"-n pihole"})," in every command), we can just set the context of the following commands to the newly-created namespace. To do this:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl config set-content --current --namespace pihole\n"})}),"\n",(0,s.jsx)(n.p,{children:"Next I tackled the subject of storage. Since Pihole requires some persistent storage for configuration files, logs and data for its SQLLite database, we need to create a place in the filesystem that will be used as the mount for the persistent storage resources we\u2019ll set up for the Pod. So I created a directory in my home directory to hold it:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir ~/pihole/data\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Make sure that you have enough space in the directory you choose (you can use ",(0,s.jsx)(n.code,{children:"df u /path/to/pihole/data"})," to verify).\nNext, we need to create some resources to bind the host (Raspberry Pi) filesystem to the Kubernetes resources which will run the Pihole container. We need to create 3 things:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Default ",(0,s.jsx)(n.code,{children:"StorageClass"})," \u2013 This is just a resource that we use to describe the different types of storage the Kubernetes deployment offers. In our case, the ",(0,s.jsx)(n.code,{children:"StorageClass"})," will be a simple one that\u2019s provisioned by the local machine."]}),"\n",(0,s.jsxs)(n.li,{children:["2 ",(0,s.jsx)(n.code,{children:"PersistentVolume"}),"s \u2013 These are abstractions of the volumes we\u2019ll be using to store the data for Pihole. We need to specify 2 of these, one for the assets stored in the /etc filesystem of the container (such as DNS server lists, domain lists , pihole FTL configuration, etc) and one for the ",(0,s.jsx)(n.code,{children:"dnsmasq"})," filesystem (includes the initial Pihole configuration)."]}),"\n",(0,s.jsxs)(n.li,{children:["2 ",(0,s.jsx)(n.code,{children:"PersistentVolumeClaim"}),"s \u2013 These are the actual requests for storage from the PVs created above."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["To create the ",(0,s.jsx)(n.code,{children:"StorageClass"}),", I defined the following specification called ",(0,s.jsx)(n.code,{children:"storageclass.yaml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: manual\nprovisioner: manual\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"volumeBindingMode: Immediate"})," ensures that upon specifying the ",(0,s.jsx)(n.code,{children:"PersistentStorage"})," to the same provisioner type (manual), the ",(0,s.jsx)(n.code,{children:"StorageClass"})," will immediately bind to it. The ",(0,s.jsx)(n.code,{children:"reclaimPolicy"})," ensures that ones the ",(0,s.jsx)(n.code,{children:"PersistentVolumeClaims"})," are discarded, so will the ",(0,s.jsx)(n.code,{children:"StorageClass"}),".\nWe can create the resource by running:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f storageclass.yaml\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Now that we have a ",(0,s.jsx)(n.code,{children:"StorageClass"})," set up, we can create the 2 PVs (",(0,s.jsx)(n.code,{children:"volume-etc.yaml"})," and ",(0,s.jsx)(n.code,{children:"volume-dnsmasq.yaml"}),", respectively):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pihole-volume\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: "/home/ubuntu/pihole/data/"\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pihole-dnsmasq\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: "/home/ubuntu/pihole/data/"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["We\u2019re defining 2 volumes with ",(0,s.jsx)(n.code,{children:"1GB"})," of storage to bind with ",(0,s.jsx)(n.code,{children:"StorageClass"})," named manual in the host filesystem path ",(0,s.jsx)(n.code,{children:"~/pihole/data"})," (same path we created in the first step above). Keep in mind this path as we\u2019ll come back to this later.\nWe can create both PVs by running:"]}),"\n",(0,s.jsxs)(n.p,{children:["The final step to set up the storage is to create the two ",(0,s.jsx)(n.code,{children:"PersistentVolumeClaims"}),". Here are the two specifications for them (",(0,s.jsx)(n.code,{children:"claim-etc.yaml"})," and ",(0,s.jsx)(n.code,{children:"claim-dnsmasq.yam"}),"l, respectively):"]}),"\n",(0,s.jsx)(n.p,{children:"And create the PVCs:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f volume-etc.yaml\nkubectl apply -f volume-dnsmasq.yaml\n"})}),"\n",(0,s.jsx)(n.p,{children:"Great, let\u2019s verify that the storage is running set up correctly. It should look something like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl get sc,pv,pvc\nNAME                                 PROVISIONER   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nstorageclass.storage.k8s.io/manual   manual        Delete          Immediate           false                  3m\nNAME                              CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                            STORAGECLASS   REASON   AGE\npersistentvolume/pihole-dnsmasq   1Gi        RWO            Retain           Bound    pihole/pihole-dnsmasq-pv-claim   manual                  2m\npersistentvolume/pihole-volume    1Gi        RWO            Retain           Bound    pihole/pihole-etc-pv-claim       manual                  2m\nNAME                                            STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/pihole-dnsmasq-pv-claim   Bound    pihole-dnsmasq   1Gi        RWO            manual         1m\npersistentvolumeclaim/pihole-etc-pv-claim       Bound    pihole-volume    1Gi        RWO            manual         1m\n"})}),"\n",(0,s.jsxs)(n.p,{children:["We can see that the ",(0,s.jsx)(n.code,{children:"PersistentVolumeClaims"}),"s are bound to their respective ",(0,s.jsx)(n.code,{children:"PersistentVolume"})," and the ",(0,s.jsx)(n.code,{children:"PersistentVolume"}),"s are bound to the ",(0,s.jsx)(n.code,{children:"StorageClass"}),". Looks good!\nNow that we have the storage set up, we need to create two more specifications:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.code,{children:"Service"})," to specify the access to Pihole."]}),"\n",(0,s.jsxs)(n.li,{children:["A ",(0,s.jsx)(n.code,{children:"Deployment"})," which will pull the latest Pihole image from Dockerhub, create a container from this image, allow the Pod to use the storage we set up to hold its data and configuration files and bind to a Service so that we can access Pihole dashboard."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Let\u2019s start with the service ",(0,s.jsx)(n.code,{children:"svc.yaml"}),". We\u2019ll expose the Pihole server externally so we can access it from within our network. To do that, we need to know our internal IP address. We can find it easily by running:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'hostname -i | cut -d " " -f1\n10.100.102.95\n'})}),"\n",(0,s.jsxs)(n.p,{children:["We can then use that value to finish off our ",(0,s.jsx)(n.code,{children:"Service"})," specifications:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"apiVersion: v1\nkind: Service\nmetadata:\n  name: pihole\nspec:\n  selector:\n    app: pihole\n  clusterIP: 10.152.183.2\n  ports:\n    - port: 80\n      targetPort: 80\n      name: pihole-admin\n    - port: 53\n      targetPort: 53\n      protocol: TCP\n      name: dns-tcp\n    - port: 53\n      targetPort: 53\n      protocol: UDP\n      name: dns-udp\n  externalIPs:\n  - 10.100.102.95\n"})}),"\n",(0,s.jsxs)(n.p,{children:["We then need to create the ",(0,s.jsx)(n.code,{children:"Deployment"})," which binds the storage and network settings together. This is what it looks like (",(0,s.jsx)(n.code,{children:"deployment.yaml"}),"):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pihole\n  labels:\n    app: pihole\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pihole\n  template:\n    metadata:\n      labels:\n        app: pihole\n        name: pihole\n    spec:\n      containers:\n        - name: pihole\n          image: pihole/pihole:latest\n          env:\n            - name: TZ\n              value: 'Asia/Jerusalem'\n            - name: WEBPASSWORD\n              value: 'YOUR_PASSWORD'\n            - name: TEMPERATUREUNIT\n              value: c\n          volumeMounts:\n            - name: pihole-local-etc-volume\n              mountPath: '/etc/pihole'\n            - name: pihole-local-dnsmasq-volume\n              mountPath: '/etc/dnsmasq.d'\n      volumes:\n        - name: pihole-local-etc-volume\n          persistentVolumeClaim:\n            claimName: pihole-etc-pv-claim\n        - name: pihole-local-dnsmasq-volume\n          persistentVolumeClaim:\n            claimName: pihole-dnsmasq-pv-claim\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Most of this is boilerplate and optional. The important sectors are the volumes where we specify the PVC bindings and the matchLabels which binds the ",(0,s.jsx)(n.code,{children:"Service"})," to the ",(0,s.jsx)(n.code,{children:"Deployment"}),". Also, you can set a password for the Pihole dashboard admin page by changing the value of ",(0,s.jsx)(n.code,{children:"spec.template.spec.containers[0].WEBPASSWORD"}),".\nI ran the following command to create the deployment:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl apply -f deployment.yaml\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Unfortunately, I noticed that the pihole ",(0,s.jsx)(n.code,{children:"Pod"})," was in a ",(0,s.jsx)(n.code,{children:"CrashLoopBackoff"}),"!"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-pihole-pod-crashloopbackoff",children:"Troubleshooting PiHole Pod CrashLoopBackOff"}),"\n",(0,s.jsxs)(n.p,{children:["The first step in troubleshooting a ",(0,s.jsx)(n.code,{children:"CrashLoopBackoff"})," is to review the ",(0,s.jsx)(n.code,{children:"Pod"})," logs. This is what I saw:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl logs pihole-64678974cd-p7spj \n# ...\n::: Preexisting ad list /etc/pihole/adlists.list detected ((exiting setup_blocklists early))\nhttps://raw.githubusercontent.com/StevenBlack/hosts/master/hosts\ndnsmasq: bad option at line 1 of /etc/dnsmasq.d/adlists.list\n::: Testing pihole-FTL DNS: [cont-init.d] 20-start.sh: exited 1.\n[cont-finish.d] executing container finish scripts...\n[cont-finish.d] done.\n[s6-finish] waiting for services.\n[s6-finish] sending all processes the TERM signal.\n"})}),"\n",(0,s.jsxs)(n.p,{children:["So it seemed that there was some sort of unexpected issue when reading a file named adlists.list. But since the ",(0,s.jsx)(n.code,{children:"Pod"})," was in a ",(0,s.jsx)(n.code,{children:"CrashLoopBackoff"}),", I could not have direct access to the Pod to check the file because it was constantly restarting.\nTherefore, I went the hard route and decided to download the pihole image to review the source code and pinpoint the failure."]}),"\n",(0,s.jsx)(n.h2,{id:"installing-docker-to-troubleshoot-image-initialization-failure",children:"Installing Docker to Troubleshoot Image Initialization Failure"}),"\n",(0,s.jsxs)(n.p,{children:["To install Docker on the Raspberry Pi, I needed to figure out first what architecture the processor is running.\nI ran the following command and found that the I was running ",(0,s.jsx)(n.code,{children:"aarch64"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"uname -m\naarch64\n"})}),"\n",(0,s.jsxs)(n.p,{children:["But when reviewing the Docker documentation how to install the engine on Ubuntu, I saw that the only tabs available were ",(0,s.jsx)(n.code,{children:"x86_64"}),"/",(0,s.jsx)(n.code,{children:"amd64"}),", ",(0,s.jsx)(n.code,{children:"armhf"})," or ",(0,s.jsx)(n.code,{children:"arm64"}),".\nSo I did some research and found that the GNU triplet for the 64-bit ISA is ",(0,s.jsx)(n.code,{children:"aarch64"}),". So essentially ",(0,s.jsx)(n.code,{children:"aarch64"})," is ",(0,s.jsx)(n.code,{children:"arm64"}),".\nI ran the following commands to install Docker:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release\necho \\\\n  "deb [arch=arm64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\\n  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt update\nsudo apt install docker-ce docker-ce-cli containerd.io\n'})}),"\n",(0,s.jsx)(n.p,{children:"I then created the pihole container:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo docker run -it pihole/pihole bash\n"})}),"\n",(0,s.jsxs)(n.p,{children:["On another ssh session, I ran the following command on the host machine to download the content of the pihole image into an archive ",(0,s.jsx)(n.code,{children:"pihole.tar"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# -l returns the latest container\n# -q quiet output\ncontainer_id=`sudo docker ps -lq`\necho $container_id\n4565bc8fe1e1\nsudo docker export $container_id -o pihole.tar\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now that I had the contents of the image, I can terminate the container by simply exiting the session created by docker run -it.\nI could then decompress the tar:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir /tmp/pihole\ntar xvf pihole.tar -C /tmp/pihole\n"})}),"\n",(0,s.jsx)(n.p,{children:"and review the source code to check why startup was failing.\nSince I knew that the failure occurs on the following line:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"::: Testing pihole-FTL DNS: [cont-init.d] 20-start.sh: exited 1.\n"})}),"\n",(0,s.jsx)(n.p,{children:"I could use the search for that particular line in the whole image filesystem I just extracted and see which file has the logic."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo grep -rnw \"Testing pihole\" ./* --exclude pihole.tar\n./bash_functions.sh:260:    echo -n '::: Testing pihole-FTL DNS: '\n"})}),"\n",(0,s.jsxs)(n.p,{children:["So we can see that this line is called in the shell script ",(0,s.jsx)(n.code,{children:"bash_functions.sh"})," in line 260. This is what the scope looks like:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"test_configs() {\n     set -e\n     echo -n '::: Testing pihole-FTL DNS: '\n     sudo -u ${DNSMASQ_USER:-root} pihole-FTL test || exit 1\n     echo -n '::: Testing lighttpd config: '\n     lighttpd -t -f /etc/lighttpd/lighttpd.conf || exit 1\n     set +e\n     echo \"::: All config checks passed, cleared for startup ...\"\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["So seems that we\u2019re running the command ",(0,s.jsx)(n.code,{children:"pihole-FTL test"}),"  as ",(0,s.jsx)(n.code,{children:"root"})," and send an exit code of 1 if the command fails (which it does in this case). The next step is to figure out what\u2019s the command: ",(0,s.jsx)(n.code,{children:"pihole-FTL test"}),".\nWe can find the binary by searching for it in the whole extracted image filesystem:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'find /tmp/pihole -name "*pihole-FTL*"\n/usr/bin/pihole-FTL\n'})}),"\n",(0,s.jsx)(n.p,{children:"I decided to recreate the container so I could interact with this binary:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Inside pihole container\nroot@371cad2a9105:/# pihole-FTL --help\npihole-FTL - The Pi-hole FTL engine\nUsage:    sudo service pihole-FTL <action>\nwhere '<action>' is one of start / stop / restart\nAvailable arguments:\n            debug           More verbose logging,\n                            don't go into daemon mode\n            test            Don't start pihole-FTL but\n                            instead quit immediately\n        -v, version         Return FTL version\n        -vv                 Return more version information\n        -t, tag             Return git tag\n        -b, branch          Return git branch\n        -f, no-daemon       Don't go into daemon mode\n        -h, help            Display this help and exit\n        dnsmasq-test        Test syntax of dnsmasq's\n                            config files and exit\n        regex-test str      Test str against all regular\n                            expressions in the database\n        regex-test str rgx  Test str against regular expression\n                            given by rgx\n        --lua, lua          FTL's lua interpreter\n        --luac, luac        FTL's lua compiler\n        dhcp-discover       Discover DHCP servers in the local\n                            network\n        sqlite3             FTL's SQLite3 shell\nOnline help: https://github.com/pi-hole/FTL\n"})}),"\n",(0,s.jsx)(n.p,{children:"The strange is that running the same command, in a Docker container where PiHole loads successfully, also returns an exit code of 1:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Inside pihole container\nroot@371cad2a9105: sudo -u pihole-FTL test;echo $?\n1\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This threw me off a bit. My main question was: How come the Docker container\u2019s initialization script finishes successfully but the same container running in a Kubernetes Pod fails?\nI had to take a step back and try to understand what\u2019s the biggest difference between the Docker method that works and the Kubernetes method that fails. The only possible differences that I could think of were (1) no port forwarding, host network on Docker (2) no presistent storage set up in Docker.\nSince I always seem to have a problem with using the ",(0,s.jsx)(n.code,{children:"StorageClass"}),", ",(0,s.jsx)(n.code,{children:"PersistentVolume"})," and ",(0,s.jsx)(n.code,{children:"PersistentVolumeClaim"})," APIs in Kubernetes, my gut told me that I had mis-configured something there.\nWhen navigating back to the mount path that I set in the PV YAML specification, I noticed that in both PVs (etc, ",(0,s.jsx)(n.code,{children:"dnsmasq"}),") I set the path to be the same, namely ",(0,s.jsx)(n.code,{children:"/home/ubuntu/pihole/data"}),". I decided I would create two different mount points, and retest it.\nBelow are the modifications I made (see comment):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# volume-etc.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pihole-volume\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: "/home/ubuntu/pihole/data/etc" # Changed from /home/ubuntu/data/\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# volume-dnsmasq.yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pihole-dnsmasq\n  labels:\n    type: local\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteOnce\n  hostPath:\n    path: "/home/ubuntu/pihole/data/dnsmasq"\n'})}),"\n",(0,s.jsx)(n.p,{children:"I recreated all Kubernetes resources after the updates and found that the Pod ran successfully!"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"watch -t kubectl get pv,pvc,sc,deploy,svc,pod\nNAME                              CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                            STORAGECLASS   REASON   AGE\npersistentvolume/pihole-dnsmasq   2Gi        RWO            Retain           Bound    pihole/pihole-dnsmasq-pv-claim   manual                  13m  \npersistentvolume/pihole-volume    2Gi        RWO            Retain           Bound    pihole/pihole-etc-pv-claim       manual                  13m  \nNAME                                            STATUS   VOLUME           CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/pihole-dnsmasq-pv-claim   Bound    pihole-dnsmasq   2Gi        RWO            manual         13m  \npersistentvolumeclaim/pihole-etc-pv-claim       Bound    pihole-volume    2Gi        RWO            manual         12m  \nNAME                                 PROVISIONER   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nstorageclass.storage.k8s.io/manual   manual        Delete          Immediate           false                  7h4m \nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/pihole   1/1     1            1           12m  \nNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                AGE\nservice/pihole   ClusterIP   10.152.183.2   10.100.102.95        80/TCP,53/TCP,53/UDP   12m  \nNAME                          READY   STATUS    RESTARTS   AGE\npod/pihole-64678974cd-mxwcw   1/1     Running   0          12m\n"})}),"\n",(0,s.jsx)(n.p,{children:"Nice! Now we have PiHole running locally on the server!\nThe last step was to ensure that we direct all DNS queries from our home network to the Pihole DNS server instead of our router."}),"\n",(0,s.jsx)(n.h2,{id:"changing-dns-settings-on-devices",children:"Changing DNS Settings on Devices"}),"\n",(0,s.jsxs)(n.p,{children:["The first device I changed was a 2013 MacBook Air running the latest Ubuntu Desktop that I used to SSH into the Raspberry Pi to set up Pihole.\nIt was quite easy to change the DNS server. Just go to ",(0,s.jsx)(n.em,{children:"WiFi > Choose currently connected WiFi network kegwheel > IPv4 tab > Disable Automatic DNS and set the IP of your Raspberry Pi IP address"})," (Search up for ",(0,s.jsx)(n.code,{children:"hostname -i"})," in this page to see the command again). After I restarted my laptop, I began seeing lots of queries getting blocked:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://tilsupport.files.wordpress.com/2021/05/image-1.png?w=1024",alt:"rpi"})}),"\n",(0,s.jsx)(n.h2,{id:"setting-up-static-ip-for-the-cluster",children:"Setting Up Static IP for the Cluster"}),"\n",(0,s.jsxs)(n.p,{children:["Unfortunately for me, I\u2019m using my ISP\u2019s router and not one I have full control of. This means that I do not have access to some of the router settings such as configuring the DNS server for the whole network and I can\u2019t also control the DHCP settings. This is an important limitation because I cannot control how the router assigns IPs and I was anticipating a scheduled job I have configured in crontab to reboot the server at some point causing the router to assign a new IP within the specified range. I needed to somehow ensure that the Raspberry Pi requests a specific (static) IP address to be assigned to it after reboot.\nTo set up a static IP address, we need to use a tool called ",(0,s.jsx)(n.a,{href:"https://netplan.io/",children:(0,s.jsx)(n.code,{children:"netplan"})}),", the default Ubuntu network configuration utility.\nBut first, we must confirm which interface we\u2019re going to configure to request the static IP for. In my case, I was connected to the router using the WiFi interface ",(0,s.jsx)(n.code,{children:"wlan0"}),". You can find yours by running ",(0,s.jsx)(n.code,{children:"ip link"})," although it\u2019s usually ",(0,s.jsx)(n.code,{children:"en0"})," for Ethernet (wired) connection and ",(0,s.jsx)(n.code,{children:"wlan0"})," for WiFi.\nNext, we can start interacting with the ",(0,s.jsx)(n.code,{children:"netplan"})," configuration.\nFirst, let\u2019s create a backup file (always good practice):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo cp /etc/netplan/50-cloud-init.yaml /etc/netplan/50-cloud-init.yaml.bak\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Next, let\u2019s open the ",(0,s.jsx)(n.code,{children:"50-cloud-init.yaml"})," configuration file to add the necessary configuration. In my case, since the interface is wlan0, I will be modifying the ",(0,s.jsx)(n.code,{children:"network.wifis.wlan0"})," object but it should be the same for ",(0,s.jsx)(n.code,{children:"network.ethernets.eth0"})," in case you use Ethernet.\nLet\u2019s open the file for editing:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo vim /etc/netplan/50-cloud-init.yaml\n"})}),"\n",(0,s.jsx)(n.p,{children:"And see the comments for the added fields:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'network:\n  ethernets:\n    eth0:\n      dhcp4: true\n      optional: true\n  version: 2\n  wifis:\n    wlan0:\n      optional: true\n      addresses: # add section\n        - 10.100.102.95/24 # add node IP\n      gateway4: 10.100.102.1 # add router IP\n      nameservers: # add section\n        addresses: [10.100.102.95, 8.8.8.8] # add node IP and Google as alternate DNS\n      access-points:\n        "YOUR_AP_NAME":\n          password: "YOUR_AP_PW"\n      dhcp4: false # true -> false\n'})}),"\n",(0,s.jsxs)(n.p,{children:["To know what\u2019s your router/gateway IP for ",(0,s.jsx)(n.code,{children:"gateway4"}),", you can run the following command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'ip route | grep default | cut -d " " -f3 | head -n1\n10.100.102.1\n'})}),"\n",(0,s.jsx)(n.p,{children:"We can then apply the changes running:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo netplan apply\n"})}),"\n",(0,s.jsx)(n.p,{children:"And we can confirm it\u2019s set up by running:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ip addr show dev wlan0\n3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether dc:a6:32:be:b8:c4 brd ff:ff:ff:ff:ff:ff\n    inet 10.100.102.95/24 brd 10.100.102.255 scope global dynamic wlan0\n       valid_lft 3550sec preferred_lft 3550sec\n"})}),"\n",(0,s.jsx)(n.p,{children:"We can then restart the Raspberry Pi for the changes to take effect. Now we\u2019ll be able to run maintenance on the device that requires restarts without breaking the whole cluster because of an incorrect address assignment by the router."}),"\n",(0,s.jsxs)(n.h2,{id:"maintenance-kubectl-drainuncordon",children:["Maintenance, ",(0,s.jsx)(n.code,{children:"kubectl drain/uncordon"})]}),"\n",(0,s.jsxs)(n.p,{children:["After about a week of running, I performed an ",(0,s.jsx)(n.code,{children:"apt upgrade"})," which required me to reboot the server for the changes to apply. I needed to take the Pihole (and the whole Raspberry Pi) down.\nTo do this, we first need to ensure that we evict all running Kubernetes resources and that we stop scheduling of new Pods to the cluster.\nWe need to run the following sequence of commands to be able to ensure that our server restart runs smoothely."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Get node name\nnode_name=`kubectl get node -o=jsonpath='{.items[0].metadata.labels}' | jq '.\"kubernetes.io/hostname\"'`\n \n# Drain node, will evict all resources\nkubectl drain $node_name --ignore-daemonsets --delete-local-data --force\n  \n# Reboot the server\nsudo reboot\n"})}),"\n",(0,s.jsxs)(n.p,{children:["After reboot, wait until ",(0,s.jsx)(n.code,{children:"kubelet.service"})," is up and run:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"node_name=`kubectl get node -o=jsonpath='{.items[0].metadata.labels}' | jq '.\"kubernetes.io/hostname\"'`\n \nkubectl uncordon $node_name\n"})}),"\n",(0,s.jsx)(n.p,{children:"We should then see that the Node is schedulable and that the all Pihole resources are back up and running."})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>l});var s=t(96540);const a={},o=s.createContext(a);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);