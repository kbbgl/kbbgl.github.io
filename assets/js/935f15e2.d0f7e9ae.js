"use strict";(globalThis.webpackChunkkgkb=globalThis.webpackChunkkgkb||[]).push([[96649],{81408:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});var o=i(74848),s=i(28453);const t={},d=void 0,r={id:"software/containerization/k8s/Scheduling/Pod_Affinity_Rules",title:"Pod_Affinity_Rules",description:"Pod Affinity Rules",source:"@site/docs/software/containerization/k8s/Scheduling/6._Pod_Affinity_Rules.md",sourceDirName:"software/containerization/k8s/Scheduling",slug:"/software/containerization/k8s/Scheduling/Pod_Affinity_Rules",permalink:"/docs/software/containerization/k8s/Scheduling/Pod_Affinity_Rules",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{},sidebar:"docsSidebar",previous:{title:"Pod_Specification",permalink:"/docs/software/containerization/k8s/Scheduling/Pod_Specification"},next:{title:"podAffinity_podAntiAffinity_Example",permalink:"/docs/software/containerization/k8s/Scheduling/podAffinity_podAntiAffinity_Example"}},l={},c=[{value:"<code>Pod</code> Affinity Rules",id:"pod-affinity-rules",level:2},{value:"<code>Node</code> Affinity",id:"node-affinity",level:3}];function a(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.h2,{id:"pod-affinity-rules",children:[(0,o.jsx)(n.code,{children:"Pod"})," Affinity Rules"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"Pod"}),"s which may communicate a lot or share data may operate best if co-located, which would be a form of ",(0,o.jsx)(n.code,{children:"affinity"}),". For greater fault tolerance, you may want ",(0,o.jsx)(n.code,{children:"Pod"}),"s to be as separate as possible, which would be ",(0,o.jsx)(n.code,{children:"anti-affinity"}),".\nThese settings are used by the scheduler based on the ",(0,o.jsx)(n.code,{children:"labels"})," of ",(0,o.jsx)(n.code,{children:"Pod"}),"s that are already running. As a result, the scheduler must interrogate each node and track the ",(0,o.jsx)(n.code,{children:"labels"})," of running ",(0,o.jsx)(n.code,{children:"Pod"}),"s. Clusters larger than several hundred nodes may see significant performance loss. ",(0,o.jsx)(n.code,{children:"Pod"})," ",(0,o.jsx)(n.code,{children:"affinity"})," rules use the following operators:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"`In"}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"NotIn"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"Exists"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"DoesNotExist"})}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"node-affinity",children:[(0,o.jsx)(n.code,{children:"Node"})," Affinity"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"requiredDuringSchedulingIgnoredDuringExecution"}),"\nMeans that the ",(0,o.jsx)(n.code,{children:"Pod"})," will not be scheduled on a node unless the following operator is true. If the operator changes to become false in the future, the ",(0,o.jsx)(n.code,{children:"Pod"})," will continue to run. This could be seen as a hard rule."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"preferredDuringSchedulingIgnoredDuringExecution"}),"\nWill choose a node with the desired setting before those without. If no properly-labeled nodes are available, the ",(0,o.jsx)(n.code,{children:"Pod"})," will execute anyway. This is more of a soft setting, which declares a preference instead of a requirement."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"podAffinity"}),"\nthe scheduler will try to schedule ",(0,o.jsx)(n.code,{children:"Pod"}),"s together."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"podAntiAffinity"}),"\nWould cause the scheduler to keep ",(0,o.jsx)(n.code,{children:"Pod"}),"s on different nodes."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"topologyKey"}),"\nAllows a general grouping of ",(0,o.jsx)(n.code,{children:"Pod"})," deployments. Affinity (or the inverse anti-affinity) will try to run on nodes with the declared topology key and running ",(0,o.jsx)(n.code,{children:"Pod"}),"s with a particular ",(0,o.jsx)(n.code,{children:"label"}),". The ",(0,o.jsx)(n.code,{children:"topologyKey"})," could be any legal key, with some important considerations."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["If using ",(0,o.jsx)(n.code,{children:"requiredDuringScheduling"})," and the admission controller ",(0,o.jsx)(n.code,{children:"LimitPodHardAntiAffinityTopology"})," setting, the ",(0,o.jsx)(n.code,{children:"topologyKey"})," must be set to ",(0,o.jsx)(n.code,{children:"kubernetes.io/hostname"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["If using ",(0,o.jsx)(n.code,{children:"PreferredDuringScheduling"}),", an empty ",(0,o.jsx)(n.code,{children:"topologyKey"})," is assumed to be all, or the combination of ",(0,o.jsx)(n.code,{children:"kubernetes.io/hostname"}),", ",(0,o.jsx)(n.code,{children:"topology.kubernetes.io/zone"})," and ",(0,o.jsx)(n.code,{children:"topology.kubernetes.io/region"}),"."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>r});var o=i(96540);const s={},t=o.createContext(s);function d(e){const n=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);